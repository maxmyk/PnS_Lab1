---
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

### *Mariana Skoropad, Maksym Mykhasyuta, Serhii Ivanov*

## Introduction

During the past three weeks, you learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

All the terms on the right-hand side can be estimated from the data as
respective relative frequencies;\
see [this
site](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)
for more detailed explanations.

## Data description

There are 5 datasets uploaded on the cms.

To determine your variant, take your team number from the list of teams
on cms and take *mod 5* - this is the number of your data set.

-   **0 - authors** This data set consists of citations of three famous
    writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP
    Lovecraft. The task with this data set is to classify a piece of
    text with the author who was more likely to write it.

-   **1 - discrimination** This data set consists of tweets that have
    discriminatory (sexism or racism) messages or of tweets that are of
    neutral mood. The task is to determine whether a given tweet has
    discriminatory mood or does not.

-   **2 - fake news** This data set contains data of American news: a
    headline and an abstract of the article. Each piece of news is
    classified as fake or credible. The task is to classify the news
    from test.csv as credible or fake.

-   **3 - sentiment** All the text messages contained in this data set
    are labeled with three sentiments: positive, neutral or negative.
    The task is to classify some text message as the one of positive
    mood, negative or neutral.

-   **4 - spam** This last data set contains SMS messages classified as
    spam or non-spam (ham in the data set). The task is to determine
    whether a given message is spam or non-spam.

Each data set consists of two files: *train.csv* and *test.csv*. The
first one you will need find the probabilities distributions for each of
the features, while the second one is needed for checking how well your
classifier works.

```{r}
# here goes a list of recommended libraries,
# though you may install other ones if they are needed
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
library(textstem)
```

## Instructions

-   The first step is data pre-processing, which includes removing
    punctuation marks and stop words

-   represent each message as a bag-of-words

-   using the training set, calculate all the conditional probabilities
    in formula (1)

-   use those to predict classes for messages in the test set

-   evaluate effectiveness of the classifier by calculating the
    corresponding metrics

-   shortly summarize your work

-   do not forget to submit both the (compiled) Rmd source file and the
    .html output

### Data pre-processing

-   Read the *.csv* data files.
-   Ð¡lear your data from punctuation or other unneeded symbols.
-   Clear you data from stop words. You don't want words as is, and, or
    etc. to affect your probabilities distributions, so it is a wise
    decision to get rid of them. Find list of stop words in the cms
    under the lab task.
-   Represent each test message as its bag-of-words. Here:
    <https://machinelearningmastery.com/gentle-introduction-bag-words-model/>
    you can find general introduction to the bag-of-words model and
    examples on to create it.
-   It is highly recommended to get familiar with R dataframes, it would
    make the work much easier to do.
-   Useful links:
    -   <https://steviep42.github.io/webscraping/book/bagofwords.html#tidytext> -
        example of using *tidytext* to count frequencies of the words.
    -   Basics of Text Mining in R:
        <http://rstudio-pubs-static.s3.amazonaws.com/256588_57b585da6c054349825cba46685d8464.html>
        . Note that it also includes an example on how to create a bag
        of words from your text document.

```{r}
list.files(getwd())
list.files("data/3-sentiment")
```

```{r}
test_path <- "data/3-sentiment/test.csv"
train_path <- "data/3-sentiment/train.csv"

stop_words <- read_file("stop_words.txt")
# https://stackoverflow.com/questions/27195912/why-does-strsplit-return-a-list
splitted_stop_words <- strsplit(stop_words, split='\n')
splitted_stop_words <- splitted_stop_words[[1]]
```

```{r}
train <-  read.csv(file = train_path, stringsAsFactors = FALSE)
test <-  read.csv(file = test_path, stringsAsFactors = FALSE)
```

```{r}
# note the power functional features of R bring us! 

# deletes everything except words
train$text <- gsub(pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = "", train$text)

#train$text[1]
#review_corpus = Corpus(VectorSource(train$text))
#train$text <- tm_map(review_corpus, textstem::lemmatize_strings)
## default
#train$text[1]

# default
tidy_text <- unnest_tokens(train, 'splitted', 'text', token="words") %>%
             filter(!splitted %in% splitted_stop_words)
#tidy_text %>% count(splitted,sort=TRUE)



globalcount <<- 0

neg_count <<- 0
neu_count <<- 0
pos_count <<- 0
neg_count1 <<- 0
neu_count1 <<- 0
pos_count1 <<- 0
```

## Naive Bayes implementation

```{r}
naiveBayes <- setRefClass("naiveBayes",
       fields = list(),
       methods = list(
                    fit = function()
                    {
                          neg_count <<- 0
                          neu_count <<- 0
                          pos_count <<- 0
                          neg_count1 <<- 0
                          neu_count1 <<- 0
                          pos_count1 <<- 0
                          data_to_work_with <<- as.data.frame.matrix(table(tidy_text$splitted, tidy_text$sentiment))
                          sum_pos <<- sum(data_to_work_with$positive)
                          sum_neg <<- sum(data_to_work_with$negative)
                          sum_neu <<- sum(data_to_work_with$neutral)
                          
                          num_words <- nrow(data_to_work_with)
                          
                          #data_to_work_with$sum <- with(data_to_work_with, negative + neutral + positive)
                          
                          data_to_work_with$p_neg <<- with(data_to_work_with, (negative + 1)/(sum_neg+num_words))
                          data_to_work_with$p_neu <<- with(data_to_work_with, (neutral + 1)/(sum_neu+num_words))
                          data_to_work_with$p_pos <<- with(data_to_work_with, (positive + 1)/(sum_pos+num_words))


test$text <- gsub(pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = "", test$text)
                    },
                    predict = function()
                    {
                      globalcount <<- 0
                      for (row in 1:nrow(test)) {
                          true_sent <- test[row, "sentiment"]
                          pred_text <- gsub("\\s+", " ", test[row, "text"])
                          pred_text <- tolower(pred_text)
                          pred_text <- trimws(pred_text)
                          pred_text <- strsplit(pred_text, " ")
                          prod_neg <- 1
                          prod_neu <- 1
                          prod_pos <- 1
                          for (elem in 1:length(pred_text[[1]])){
                            cur_elem <- pred_text[[1]][elem]
                            if (!is.na(data_to_work_with[cur_elem, "p_neg"]) & !is.na(data_to_work_with[cur_elem, "p_neu"])&!is.na(data_to_work_with[cur_elem, "p_pos"])){
                              prod_neg <- prod_neg * data_to_work_with[cur_elem, "p_neg"]
                              prod_neu <- prod_neu * data_to_work_with[cur_elem, "p_neu"]
                              prod_pos <- prod_pos * data_to_work_with[cur_elem, "p_pos"]
                            }
                            else{
                              prod_neg <- prod_neg / 3
                              prod_neu <- prod_neu / 3
                              prod_pos <- prod_pos / 3
                            }
                          }
                          if (!is.na(prod_neg) & !is.na(prod_neu)&!is.na(prod_pos)){
                            if (max(prod_neg, prod_neu, prod_pos) == prod_neg) {
                              ans <- "negative"
                              neg_count <<- neg_count + 1
                            }
                            else if (max(prod_neg, prod_neu, prod_pos) == prod_neu) {
                              ans <- "neutral"
                              neu_count <<- neu_count + 1
                            }
                            else{
                              ans <- "positive"
                              pos_count <<- pos_count + 1
                            }
                            if (ans==true_sent){
                              globalcount <<- globalcount + 1
                              if (max(prod_neg, prod_neu, prod_pos) == prod_neg) {
                                ans <- "negative"
                                neg_count1 <<- neg_count1 + 1
                              }
                              else if (max(prod_neg, prod_neu, prod_pos) == prod_neu) {
                                ans <- "neutral"
                                neu_count1 <<- neu_count1 + 1
                              }
                              else{
                                ans <- "positive"
                                pos_count1 <<- pos_count1 + 1
                              }
                            }
                            # else{
                            #   #print(paste(ans, true_sent))
                            # }
                          }
                          #print(paste(prod_neg, prod_neu, prod_pos))
                      }
                      
                      # 0.331435079726651 #without numbers and symbols
                      # 0.330296127562642
                    },
                    score = function(X_test, y_test)
                    {
                        print("Accuracy")
                        # print(paste(globalcount))
                        # print(paste(nrow(test)))
                      
                        print(paste(globalcount/(nrow(test))))
                        print("Accuracy of data: relations between truly spotted sentiments of words and wrongly")
                            data <- as.matrix(data.frame(
                                 Negative = neg_count1/(neg_count),
                                 Neutral = neu_count1/(neu_count),
                                  Positive = pos_count1/(pos_count)))
                                
                            barplot(data,col = c("#1b98e0", "#353436"))
                            print("All data: amount of words stated for each sentiment")
                            data <- as.matrix(data.frame(
                                 Negative = sum_neg/(sum_neg + sum_neu + sum_pos),
                                 Neutral = sum_neu/(sum_neg + sum_neu + sum_pos),
                                  Positive = sum_pos/(sum_neg + sum_neu + sum_pos)))
                                
                            barplot(data,col = c("#1b98e0", "#353436"))
                            print("Probability distributions")

                            data <- as.matrix(data.frame(
                                 Probabilities = c(sum_neg/(sum_neg + sum_neu + sum_pos),sum_neu/(sum_neg + sum_neu + sum_pos),sum_pos/(sum_neg + sum_neu + sum_pos))))
                                
                            barplot(data,col = c("#1b98e0", "#353436", "#ffcccb"), width = c(3))
                                legend("center",
           legend = c("Negative", "Neutral", "Positive"),
           fill = c("#1b98e0", "#353436", "#ffcccb"))
            
                    }
))

model = naiveBayes()
model$fit()
model$predict()
model$score()
```

## Conclusions

In general, first we pre-process train which includes finding conditional probabilities of a word given sentiment, by applying laplace smoothing to it. We are assuming that every word is independent, so we can find if their intersection belongs to a certain sentiment.

Pros: is easy to implement and understand

Cons: insufficient data worsens the results. For example in this train dataset we had only 3% of negative messages, when test dataset had over 50%). So the ratio of negative sentiment in train was not representative to the data in test. And our classifier knew very little about all negative words.
Over all, we got 33% accuracy.